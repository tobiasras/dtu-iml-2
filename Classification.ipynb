{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.clean_data import clean_data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('data/diamond.csv')\n",
    "\n",
    "# Define target\n",
    "y = data['color']\n",
    "\n",
    "# perform one hot encoding and log transforms for carat and price\n",
    "df = clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which feature is best for classification problem\n",
    "def check_class_distribution(df, column_name):\n",
    "    class_counts = df[column_name].value_counts()\n",
    "    class_percentages = df[column_name].value_counts(normalize=True) * 100\n",
    "\n",
    "    print(f\"Class distribution for {column_name}:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        percentage = class_percentages[cls]\n",
    "        print(f\"Class {cls}: {count} ({percentage:.2f}%)\")\n",
    "\n",
    "check_class_distribution(df, 'color')\n",
    "check_class_distribution(df, 'clarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the old carat and price columns along with target color\n",
    "df = df.drop(columns=['carat', 'price', 'color'])\n",
    "\n",
    "# standardize the data\n",
    "df = (df - df.mean()) / df.std()\n",
    "X = df.values\n",
    "#X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.arange(2, 20, 1) # Tree depth range\n",
    "\n",
    "K = 10 # Number of folds\n",
    "CV = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error storage variables\n",
    "Error_train = np.empty((len(max_depths), K))\n",
    "Error_test = np.empty((len(max_depths), K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation and model training loop\n",
    "k = 0\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    for i, depth in enumerate(max_depths):\n",
    "        model = DecisionTreeClassifier(criterion='gini', max_depth=depth)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        Error_train[i, k] = np.mean(y_train_pred != y_train)\n",
    "        Error_test[i, k] = np.mean(y_test_pred != y_test)\n",
    "\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.boxplot(Error_test.T)\n",
    "plt.xlabel(\"Model complexity (max tree depth)\")\n",
    "plt.ylabel(f\"Test error across CV folds (K={K})\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(max_depths, Error_train.mean(axis=1), label='Train Error')\n",
    "plt.plot(max_depths, Error_test.mean(axis=1), label='Test Error')\n",
    "plt.xlabel(\"Model complexity (max tree depth)\")\n",
    "plt.ylabel(f\"Error (misclassification rate, CV K={K})\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
