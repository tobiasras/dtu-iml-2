{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1ea28e",
   "metadata": {},
   "source": [
    "## Import and clean data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a142e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.clean_data import clean_data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "df = pd.read_csv('data/diamond.csv')\n",
    "\n",
    "# performs interger encoding and log transforms carat and price.\n",
    "df = clean_data(df)\n",
    "\n",
    "Y_price = df['price'].values\n",
    "\n",
    "df = df.drop([\"carat\", \"price\"], axis=1)\n",
    "\n",
    "df = (df - df.mean() ) / df.std(ddof=1)\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With log price\n",
    "Y = df['log_price'].values\n",
    "\n",
    "# with price\n",
    "#Y = Y_price\n",
    "\n",
    "feature_names = df.columns\n",
    "\n",
    "df = df.drop('log_price', axis=1)\n",
    "\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f238d8b",
   "metadata": {},
   "source": [
    "## Find the best regulzeration paramaetetr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0749dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "reg_tries = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 10, 100, 1000, 5000, 10000]\n",
    "results = []\n",
    "\n",
    "for reg_value in reg_tries: \n",
    "    ridge_model = Ridge(alpha=reg_value)\n",
    "    \n",
    "    scores = cross_val_score(ridge_model, X_train, Y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n",
    "    \n",
    "    mean_rmse = -scores.mean()  # Convert negative RMSE back to positive\n",
    "    results.append((reg_value, mean_rmse))\n",
    "    print(f\"Regularization: {reg_value:<10} Cross-Validation RMSE: {mean_rmse:.8f}\")\n",
    "\n",
    "reg_values, rmse_values = zip(*results)\n",
    "\n",
    "# optimal reg model # with lowest RSME\n",
    "opt_reg = reg_values[rmse_values.index(min(rmse_values))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train model with all features and optimal reg we found\n",
    "model = Ridge(alpha=opt_reg)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for the test set\n",
    "test_rmse_all_features = np.sqrt(mean_squared_error(Y_test, y_pred))\n",
    "\n",
    "print(\"\\nFinal model :\")\n",
    "print(f\"Test RMSE: {test_rmse_all_features:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(reg_values, rmse_values, marker='o', linestyle='-', color='b')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Regularization Strength (alpha)')\n",
    "plt.ylabel('Cross-Validation RMSE')\n",
    "plt.title('Effect of Regularization on RMSE')\n",
    "plt.grid(True)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3152c",
   "metadata": {},
   "source": [
    "# Feature selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2906a741",
   "metadata": {},
   "source": [
    "Backwards selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592058ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Backward selection: Start with all features and remove one at a time\n",
    "backward_selector = SequentialFeatureSelector(\n",
    "    Ridge(alpha=opt_reg),  # model with optimal reg.\n",
    "    n_features_to_select=\"auto\",\n",
    "    direction=\"backward\", \n",
    "    cv=10, \n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "backward_selector.fit(X_train, Y_train)\n",
    "\n",
    "# Get selected feature indices\n",
    "selected_backward_features = backward_selector.get_support(indices=True)\n",
    "print(f\"Selected Features (Backward): {selected_backward_features}\")\n",
    "\n",
    "\n",
    "X_train_backward = X_train[:, selected_backward_features]\n",
    "\n",
    "# backward model evaluate\n",
    "backward_score = cross_val_score(Ridge(alpha=opt_reg), X_train_backward, Y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "print(\"Backward score:\", -backward_score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd31d46",
   "metadata": {},
   "source": [
    "Forward Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e093c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward selection: Start with no features and add one at a time\n",
    "forward_selector = SequentialFeatureSelector(\n",
    "    Ridge(alpha=opt_reg),  # model with optimal reg.\n",
    "    n_features_to_select=\"auto\",\n",
    "    direction=\"forward\", \n",
    "    cv=10, \n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "forward_selector.fit(X_train, Y_train)\n",
    "\n",
    "# Get selected feature indices\n",
    "selected_forward_features = forward_selector.get_support(indices=True)\n",
    "print(f\"Selected Features (Forward): {selected_forward_features}\")\n",
    "\n",
    "X_train_forward = X_train[:, selected_forward_features]\n",
    "\n",
    "# Forward model evaluation\n",
    "forward_score = cross_val_score(Ridge(alpha=opt_reg), X_train_forward, Y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "print(\"Forward score:\", -forward_score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4e269",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train forward model\n",
    "model_forward = Ridge(alpha=opt_reg)\n",
    "model_forward.fit(X_train_forward, Y_train)\n",
    "# Predict and calculate RMSE for forward model\n",
    "y_pred_forward = model_forward.predict(X_test[:, selected_forward_features])\n",
    "test_rmse_forward = np.sqrt(mean_squared_error(Y_test, y_pred_forward))\n",
    "\n",
    "# Train backward model\n",
    "model_backward = Ridge(alpha=opt_reg)\n",
    "model_backward.fit(X_train_backward, Y_train)\n",
    "# Predict and calculate RMSE for backward model\n",
    "y_pred_backward = model_backward.predict(X_test[:, selected_backward_features])\n",
    "test_rmse_backward = np.sqrt(mean_squared_error(Y_test, y_pred_backward))\n",
    "\n",
    "\n",
    "# Calculate R^2 values\n",
    "r2_all_features = model.score(X_test, Y_test)\n",
    "r2_forward = model_forward.score(X_test[:, selected_forward_features], Y_test)\n",
    "r2_backward = model_backward.score(X_test[:, selected_backward_features], Y_test)\n",
    "\n",
    "# Print R^2 values\n",
    "print(f\"R^2 All features          : {r2_all_features:.8f}\")\n",
    "print(f\"R^2 Forward model         : {r2_forward:.8f}\")\n",
    "print(f\"R^2 Backward model        : {r2_backward:.8f}\")\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nTest RMSE All features          : {test_rmse_all_features:.8f}\")\n",
    "print(f\"Test RMSE Forward model         : {test_rmse_forward:.8f}\")\n",
    "print(f\"Test RMSE Backward model        : {test_rmse_backward:.8f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nForward Model Feature Weights:\")\n",
    "# print feature weight for all features model\n",
    "weights = model.coef_\n",
    "for name, weight in zip(feature_names, weights):\n",
    "    print(f\"Feature: {name:<10} Weight: {weight:.8f}\")\n",
    "\n",
    "\n",
    "# Print feature weights for forward model\n",
    "print(\"\\nForward Model Feature Weights:\")\n",
    "forward_weights = model_forward.coef_\n",
    "for name, weight in zip(feature_names[selected_forward_features], forward_weights):\n",
    "    print(f\"Feature: {name:<10} Weight: {weight:.8f}\")\n",
    "\n",
    "# Print feature weights for backward model\n",
    "print(\"\\nBackward Model Feature Weights:\")\n",
    "backward_weights = model_backward.coef_\n",
    "for name, weight in zip(feature_names[selected_backward_features], backward_weights):\n",
    "    print(f\"Feature: {name:<10} Weight: {weight:.8f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
